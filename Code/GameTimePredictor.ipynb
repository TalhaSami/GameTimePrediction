{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#Standard data-sci libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKLearn\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor, ExtraTreesClassifier, BaggingRegressor, GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, HuberRegressor, Lars, LassoLars,  ElasticNet, PassiveAggressiveRegressor, RANSACRegressor, SGDRegressor, TheilSenRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor \n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#XGBoost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with outliers\n",
    "def clean_outliers(df, col):\n",
    "    iqr = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "    tolerance_threshold = 2\n",
    "    low  = df[col].quantile(0.25) - tolerance_threshold*iqr\n",
    "    high = df[col].quantile(0.75) + tolerance_threshold*iqr\n",
    "    df_cleaned = df.loc[(df[col] > low) & (df[col] < high)]\n",
    "    return df_cleaned\n",
    "\n",
    "def rmse(a,b):\n",
    "    return metrics.mean_squared_error(a,b)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (\"../train.csv\")\n",
    "test_data = (\"../test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data\n",
    "df = pd.read_csv(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning and preprocessing train data\n",
    "df = pd.read_csv(train_data)\n",
    "\n",
    "#remove columns with more than a certain proprotion of missing values\n",
    "missing_value_proportion = 0.75\n",
    "df = df[df.columns[df.isnull().mean() < missing_value_proportion]]\n",
    "df = df.loc[df.isnull().mean(axis=1) < missing_value_proportion]\n",
    "\n",
    "#drop rows with NaNs\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#replace booleans with ints\n",
    "df.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "df[\"purchase_date\"] = pd.to_datetime(df[\"purchase_date\"])\n",
    "df[\"release_date\"] = pd.to_datetime(df[\"release_date\"]) \n",
    "\n",
    "df['release_year'] = pd.DatetimeIndex(df['release_date']).year\n",
    "df['release_month'] = pd.DatetimeIndex(df['release_date']).month\n",
    "df['release_day'] = pd.DatetimeIndex(df['release_date']).day\n",
    "df['release_weekday'] = pd.DatetimeIndex(df['release_date']).dayofweek\n",
    "df['purchase_year'] = pd.DatetimeIndex(df['purchase_date']).year\n",
    "df['purchase_month'] = pd.DatetimeIndex(df['purchase_date']).month\n",
    "df['purchase_day'] = pd.DatetimeIndex(df['purchase_date']).day\n",
    "df['purchase_weekday'] = pd.DatetimeIndex(df['purchase_date']).dayofweek\n",
    "\n",
    "df[\"purchase_release_diff\"] = df.apply(lambda a: (a[\"purchase_date\"] - a[\"release_date\"]).days, axis=1)\n",
    "\n",
    "df[\"purchase_release_diff_year\"] = df[\"purchase_date\"].dt.year - df[\"release_date\"].dt.year\n",
    "\n",
    "df.drop(columns=[\"purchase_date\", \"release_date\"], inplace=True)\n",
    "\n",
    "df[\"positive_ratio\"] = df.apply(lambda a: a[\"total_positive_reviews\"]\\\n",
    "                                               /(a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"])\\\n",
    "                                               if a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"] != 0\\\n",
    "                                               else 0.5, axis=1)\n",
    "\n",
    "df[\"negative_ratio\"] = df.apply(lambda a: a[\"total_negative_reviews\"]\\\n",
    "                                               /(a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"])\\\n",
    "                                               if a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"] != 0\\\n",
    "                                               else 0.5, axis=1)\n",
    "\n",
    "df[\"total_reviews\"] = df.apply(lambda a: (a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"]),\\\n",
    "                                               axis=1)\n",
    "\n",
    "df.drop(columns=[\"total_positive_reviews\", \"total_negative_reviews\"], inplace=True)\n",
    "\n",
    "genres = df[\"genres\"].str.get_dummies(\",\")\n",
    "genres.columns = ['genre_' + str(col) for col in genres.columns]\n",
    "categories = df[\"categories\"].str.get_dummies(\",\")\n",
    "categories.columns = ['category_' + str(col) for col in categories.columns]\n",
    "tags = df[\"tags\"].str.get_dummies(\",\")\n",
    "tags.columns = ['tag_' + str(col) for col in tags.columns]\n",
    "preprocessed_df = pd.concat([df, genres, categories, tags], axis=1)\n",
    "\n",
    "preprocessed_df.drop(columns=[\"id\", \"is_free\", \"genres\", \"categories\", \"tags\"], inplace=True)\n",
    "\n",
    "preprocessed_df[[\"total_reviews\", \"price\"]] = preprocessed_df[[\"total_reviews\", \"price\"]].astype(\"int\")\n",
    "\n",
    "preprocessed_df = clean_outliers(preprocessed_df,'price')\n",
    "preprocessed_df = preprocessed_df[preprocessed_df['playtime_forever'] < 60]\n",
    "preprocessed_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "test_df = pd.read_csv(test_data, parse_dates = ['purchase_date', 'release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning and preprocessing test data\n",
    "test_df[\"purchase_date\"] = pd.to_datetime(test_df[\"purchase_date\"])\n",
    "test_df[\"release_date\"] = pd.to_datetime(test_df[\"release_date\"])\n",
    "\n",
    "test_df['release_year'] = pd.DatetimeIndex(test_df['release_date']).year\n",
    "test_df['release_month'] = pd.DatetimeIndex(test_df['release_date']).month\n",
    "test_df['release_day'] = pd.DatetimeIndex(test_df['release_date']).day\n",
    "test_df['release_weekday'] = pd.DatetimeIndex(test_df['release_date']).dayofweek\n",
    "test_df['purchase_year'] = pd.DatetimeIndex(test_df['purchase_date']).year\n",
    "test_df['purchase_month'] = pd.DatetimeIndex(test_df['purchase_date']).month\n",
    "test_df['purchase_day'] = pd.DatetimeIndex(test_df['purchase_date']).day\n",
    "test_df['purchase_weekday'] = pd.DatetimeIndex(test_df['purchase_date']).dayofweek\n",
    "\n",
    "test_df[\"purchase_release_diff\"] = test_df.apply(lambda a: (a[\"purchase_date\"] - a[\"release_date\"]).days, axis=1)\n",
    "\n",
    "test_df[\"purchase_release_diff_years\"] = test_df[\"purchase_date\"].dt.year - test_df[\"release_date\"].dt.year\n",
    "\n",
    "test_df.drop(columns=[\"purchase_date\", \"release_date\"], inplace=True)\n",
    "\n",
    "test_df[\"purchase_release_diff_years\"].fillna(test_df[\"purchase_release_diff_years\"].median(), inplace=True)\n",
    "test_df[\"purchase_release_diff\"].fillna(test_df[\"purchase_release_diff\"].median(), inplace=True)\n",
    "test_df[\"total_positive_reviews\"].fillna(test_df[\"total_positive_reviews\"].median(), inplace=True)\n",
    "test_df[\"total_negative_reviews\"].fillna(test_df[\"total_negative_reviews\"].median(), inplace=True)\n",
    "\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_df.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "test_df[\"positive_ratio\"] = test_df.apply(lambda a: a[\"total_positive_reviews\"]\\\n",
    "                                               /(a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"])\\\n",
    "                                               if a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"] != 0\\\n",
    "                                               else 0.5, axis=1)\n",
    "\n",
    "\n",
    "test_df[\"negative_ratio\"] = test_df.apply(lambda a: a[\"total_negative_reviews\"]\\\n",
    "                                               /(a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"])\\\n",
    "                                               if a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"] != 0\\\n",
    "                                               else 0.5, axis=1)\n",
    "\n",
    "test_df[\"total_reviews\"] = test_df.apply(lambda a: (a[\"total_negative_reviews\"] + a[\"total_positive_reviews\"]),\\\n",
    "                                               axis=1)\n",
    "\n",
    "test_df.drop(columns=[\"total_positive_reviews\", \"total_negative_reviews\"], inplace=True)\n",
    "\n",
    "genres_test = test_df[\"genres\"].str.get_dummies(\",\")\n",
    "genres_test.columns = ['genre_' + str(col) for col in genres_test.columns]\n",
    "categories_test = test_df[\"categories\"].str.get_dummies(\",\")\n",
    "categories_test.columns = ['category_' + str(col) for col in categories_test.columns]\n",
    "tags_test = test_df[\"tags\"].str.get_dummies(\",\")\n",
    "tags_test.columns = ['tag_' + str(col) for col in tags_test.columns]\n",
    "preprocessed_test_df = pd.concat([test_df, genres_test, categories_test, tags_test], axis=1)\n",
    "\n",
    "preprocessed_test_df.drop(columns=[\"id\",\"is_free\", \"genres\", \"categories\", \"tags\"], inplace=True)\n",
    "\n",
    "preprocessed_test_df[[\"total_reviews\", \"price\"]] = preprocessed_test_df[[\"total_reviews\", \"price\"]].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = preprocessed_df.drop(['playtime_forever'], axis=1)\n",
    "train_y = preprocessed_df['playtime_forever']\n",
    "test_x = preprocessed_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_x.columns.tolist()\n",
    "for train_feature in train_x.columns.tolist():\n",
    "    if train_feature not in test_features:\n",
    "        test_x[train_feature] = 0\n",
    "\n",
    "train_features = train_x.columns.tolist()\n",
    "for test_feature in test_x.columns.tolist():\n",
    "    if test_feature not in train_features:\n",
    "        test_x.drop(columns=[test_feature],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.fillna(test_x.median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 375) (90, 375) (339,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape,test_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_x,train_y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 375) (68, 375) (68,) (271,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,Y_test.shape,Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "X_train = mm_scaler.fit_transform(X_train)\n",
    "X_test = mm_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allmodels():\n",
    "    classifiers = [\n",
    "    AdaBoostRegressor(),\n",
    "    BaggingRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    PassiveAggressiveRegressor(),\n",
    "    SGDRegressor(),\n",
    "    TheilSenRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    DecisionTreeRegressor(),\n",
    "    ExtraTreeRegressor()\n",
    "]\n",
    "    names = [\n",
    "    \"AdaBoostRegressor\",\n",
    "    \"BaggingRegressor\",\n",
    "    \"ExtraTreesRegressor\",\n",
    "    \"GradientBoostingRegressor\",\n",
    "    \"RandomForestRegressor\",\n",
    "    \"PassiveAggressiveRegressor\",\n",
    "    \"SGDRegressor\",\n",
    "    \"TheilSenRegressor\",\n",
    "    \"KNeighborsRegressor\",\n",
    "    \"DecisionTreeRegressor\",\n",
    "    \"ExtraTreeRegressor\"\n",
    "]\n",
    "    return classifiers,names\n",
    "classifiers,names=allmodels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                rmse\n",
      "SGDRegressor                2.688517\n",
      "KNeighborsRegressor         2.964260\n",
      "ExtraTreesRegressor         3.359611\n",
      "AdaBoostRegressor           3.440684\n",
      "ExtraTreeRegressor          4.369051\n",
      "BaggingRegressor            4.541529\n",
      "RandomForestRegressor       4.975691\n",
      "PassiveAggressiveRegressor  4.981368\n",
      "GradientBoostingRegressor   5.176601\n",
      "TheilSenRegressor           7.713475\n",
      "DecisionTreeRegressor       9.670079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                rmse\n",
      "SGDRegressor                2.661362\n",
      "KNeighborsRegressor         2.964260\n",
      "ExtraTreesRegressor         3.335569\n",
      "PassiveAggressiveRegressor  3.578486\n",
      "AdaBoostRegressor           3.883143\n",
      "ExtraTreeRegressor          4.573147\n",
      "BaggingRegressor            4.761577\n",
      "GradientBoostingRegressor   4.870869\n",
      "RandomForestRegressor       5.004533\n",
      "DecisionTreeRegressor       5.030778\n",
      "TheilSenRegressor           7.713475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 rmse\n",
      "SGDRegressor                 2.732212\n",
      "ExtraTreesRegressor          2.871664\n",
      "KNeighborsRegressor          2.964260\n",
      "AdaBoostRegressor            3.500330\n",
      "ExtraTreeRegressor           3.947558\n",
      "BaggingRegressor             4.072061\n",
      "GradientBoostingRegressor    4.830671\n",
      "PassiveAggressiveRegressor   5.001525\n",
      "RandomForestRegressor        5.981867\n",
      "TheilSenRegressor            7.713475\n",
      "DecisionTreeRegressor       11.260459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                rmse\n",
      "SGDRegressor                2.490569\n",
      "KNeighborsRegressor         2.964260\n",
      "ExtraTreesRegressor         3.169299\n",
      "AdaBoostRegressor           3.579392\n",
      "ExtraTreeRegressor          4.000032\n",
      "PassiveAggressiveRegressor  4.318926\n",
      "BaggingRegressor            4.571840\n",
      "RandomForestRegressor       4.617190\n",
      "GradientBoostingRegressor   4.951320\n",
      "TheilSenRegressor           7.713475\n",
      "DecisionTreeRegressor       9.733892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                rmse\n",
      "SGDRegressor                2.514484\n",
      "KNeighborsRegressor         2.964260\n",
      "AdaBoostRegressor           3.751924\n",
      "ExtraTreesRegressor         3.796040\n",
      "PassiveAggressiveRegressor  4.211945\n",
      "RandomForestRegressor       4.472590\n",
      "GradientBoostingRegressor   4.755455\n",
      "ExtraTreeRegressor          4.916343\n",
      "BaggingRegressor            5.580810\n",
      "TheilSenRegressor           7.713475\n",
      "DecisionTreeRegressor       7.964250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                rmse\n",
      "SGDRegressor                2.379917\n",
      "KNeighborsRegressor         2.964260\n",
      "AdaBoostRegressor           3.467721\n",
      "ExtraTreesRegressor         3.892705\n",
      "GradientBoostingRegressor   4.390085\n",
      "RandomForestRegressor       4.418415\n",
      "ExtraTreeRegressor          5.139208\n",
      "BaggingRegressor            5.181911\n",
      "PassiveAggressiveRegressor  5.202461\n",
      "TheilSenRegressor           7.713475\n",
      "DecisionTreeRegressor       8.873322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                rmse\n",
      "SGDRegressor                2.515214\n",
      "KNeighborsRegressor         2.964260\n",
      "ExtraTreesRegressor         3.268196\n",
      "AdaBoostRegressor           3.368789\n",
      "ExtraTreeRegressor          3.785864\n",
      "RandomForestRegressor       5.281030\n",
      "GradientBoostingRegressor   5.444391\n",
      "BaggingRegressor            5.691904\n",
      "PassiveAggressiveRegressor  6.621171\n",
      "TheilSenRegressor           7.713475\n",
      "DecisionTreeRegressor       9.160586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                rmse\n",
      "SGDRegressor                2.802681\n",
      "KNeighborsRegressor         2.964260\n",
      "ExtraTreesRegressor         3.555549\n",
      "AdaBoostRegressor           3.565468\n",
      "ExtraTreeRegressor          3.616393\n",
      "PassiveAggressiveRegressor  3.713284\n",
      "BaggingRegressor            4.606772\n",
      "RandomForestRegressor       4.808504\n",
      "GradientBoostingRegressor   5.197594\n",
      "DecisionTreeRegressor       5.903666\n",
      "TheilSenRegressor           7.713475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                rmse\n",
      "SGDRegressor                2.841485\n",
      "KNeighborsRegressor         2.964260\n",
      "AdaBoostRegressor           3.444929\n",
      "ExtraTreesRegressor         3.455291\n",
      "BaggingRegressor            4.075843\n",
      "GradientBoostingRegressor   4.388394\n",
      "RandomForestRegressor       4.813466\n",
      "DecisionTreeRegressor       4.834594\n",
      "ExtraTreeRegressor          4.890253\n",
      "TheilSenRegressor           7.713475\n",
      "PassiveAggressiveRegressor  7.939656\n",
      "                                rmse\n",
      "SGDRegressor                2.643687\n",
      "KNeighborsRegressor         2.964260\n",
      "PassiveAggressiveRegressor  3.466936\n",
      "ExtraTreesRegressor         3.641744\n",
      "AdaBoostRegressor           3.694199\n",
      "RandomForestRegressor       4.514321\n",
      "ExtraTreeRegressor          4.559779\n",
      "BaggingRegressor            4.669502\n",
      "GradientBoostingRegressor   4.789215\n",
      "DecisionTreeRegressor       4.903349\n",
      "TheilSenRegressor           7.713475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for i in range(epochs):  \n",
    "    result=[]\n",
    "    for classifier,name in zip(classifiers,names):\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        a=classifier.predict(X_test)\n",
    "        a[a<0]=0\n",
    "        result.append(rmse(a,Y_test))\n",
    "    model_result=pd.DataFrame(data=result,index=names,columns=['rmse']).sort_values(by=\"rmse\" , ascending=True)\n",
    "    print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:39:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "rmse 2.0664659783768795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = xgb.XGBRegressor(learning_rate=0.05\n",
    "                                 , max_depth=12, n_estimators=10, alpha=10, objective ='reg:linear', colsample_bytree = 0.3\n",
    "                                )\n",
    "xgboost_model.fit(X_train,Y_train)\n",
    "y_pred = xgboost_model.predict(X_test)\n",
    "print('rmse',mean_squared_error(Y_test,y_pred)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.52853477, 0.5889439 , 0.71982557, 0.52202225, 0.863444  ,\n",
       "       1.0173299 , 1.0812002 , 0.63105184, 0.9593348 , 0.6659932 ,\n",
       "       3.3110316 , 2.5654776 , 2.0610678 , 1.539451  , 2.6463323 ,\n",
       "       1.8040519 , 0.87598026, 0.70934516, 0.9403275 , 0.63006604,\n",
       "       0.90972054, 0.890044  , 0.58369195, 0.7236235 , 0.7236235 ,\n",
       "       0.7385099 , 0.86111873, 0.74947464, 1.0979857 , 0.9506979 ,\n",
       "       1.4629277 , 0.9411022 , 2.64835   , 0.7889987 , 0.96297383,\n",
       "       0.7485833 , 0.67181635, 0.83631015, 1.0519717 , 2.8399775 ,\n",
       "       0.79259014, 0.7398387 , 1.0070097 , 0.67181635, 1.1784291 ,\n",
       "       2.9788709 , 0.6509014 , 1.0296044 , 2.561041  , 1.7969348 ,\n",
       "       0.91622424, 0.70863783, 0.51809007, 1.037403  , 0.94044626,\n",
       "       1.9613305 , 2.8308995 , 0.96630543, 1.4831593 , 0.74061334,\n",
       "       1.0239747 , 1.478186  , 0.7554635 , 0.8022088 , 0.67181635,\n",
       "       0.9347919 , 3.3079462 , 1.0233188 , 1.5981816 , 0.7754525 ,\n",
       "       0.70863783, 1.3884393 , 1.0173299 , 2.8952239 , 0.7554635 ,\n",
       "       0.88508123, 2.8975973 , 0.6009625 , 1.5206397 , 0.73985595,\n",
       "       0.7554635 , 0.99804413, 0.66297233, 0.807559  , 0.8140358 ,\n",
       "       2.6230974 , 1.4186031 , 0.91638225, 0.55066264, 0.5968998 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_predictions = xgboost_model.predict(test_x.as_matrix())\n",
    "xgb_predictions[xgb_predictions<0]=0\n",
    "xgb_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9119469026637157 1.1919639\n"
     ]
    }
   ],
   "source": [
    "print(train_y.mean(), xgb_predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=KNeighborsRegressor()\n",
    "classifier.fit(X_train,Y_train)\n",
    "predictions=classifier.predict(X_test)\n",
    "predictions[predictions<0]=0\n",
    "result.append(rmse(predictions,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.55666667, 2.55666667, 2.45666667, 1.50333333, 0.17      ,\n",
       "       2.55666667, 2.55666667, 0.        , 2.55666667, 0.        ,\n",
       "       2.22      , 1.60333333, 2.55666667, 0.17      , 0.17      ,\n",
       "       0.84333333, 2.55666667, 2.55666667, 2.55666667, 2.55666667,\n",
       "       1.60333333, 2.55666667, 2.55666667, 2.55666667, 1.60333333,\n",
       "       2.45666667, 2.22      , 2.55666667, 2.55666667, 2.55666667,\n",
       "       2.55666667, 0.17      , 2.55666667, 2.55666667, 1.67333333,\n",
       "       2.55666667, 0.17      , 0.17      , 2.55666667, 0.        ,\n",
       "       0.17      , 0.17      , 2.41666667, 2.55666667, 2.55666667,\n",
       "       2.55666667, 2.55666667, 1.60333333, 0.17      , 0.20333333,\n",
       "       0.44      , 0.17      , 2.55666667, 2.55666667, 0.17      ,\n",
       "       1.60333333, 0.17      , 2.45666667, 0.44      , 2.55666667,\n",
       "       2.55666667, 2.55666667, 1.60333333, 1.77333333, 1.60333333,\n",
       "       2.55666667, 0.44      , 0.95333333, 0.95333333, 1.60333333,\n",
       "       0.95333333, 0.17      , 0.17      , 0.17      , 2.55666667,\n",
       "       0.17      , 0.17      , 0.17      , 0.95333333, 2.45666667,\n",
       "       2.55666667, 2.22      , 1.60333333, 0.17      , 1.77333333,\n",
       "       0.17      , 2.45666667, 0.17      , 0.44      , 2.55666667])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mm_scaler.fit_transform(test_x)\n",
    "knn_predictions=classifier.predict(test_x)\n",
    "knn_predictions[knn_predictions<0]=0\n",
    "knn_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9119469026637157 1.5514444445155557\n"
     ]
    }
   ],
   "source": [
    "print(train_y.mean(),knn_predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3734287894361112\n",
      "[4.27530163 5.6433622  5.19072769 0.         2.89905499 1.76906698\n",
      " 4.66190683 4.52551112 2.93863559 5.36440687 1.7899387  1.57734231\n",
      " 0.         0.48691779 0.48761997 0.         0.         3.53199547\n",
      " 0.         5.41290869 1.37809278 4.0977998  5.14179296 1.98220272\n",
      " 0.16746216 0.63185649 1.4324926  0.         0.         0.8529277\n",
      " 0.84558243 1.85093784 2.82895046 0.         0.         3.5886966\n",
      " 0.         0.72923574 2.5515111  0.         0.81256729 4.01665507\n",
      " 0.         4.69670655 1.43475714 0.52248278 0.         4.05910213\n",
      " 0.36042722 0.92555129 0.         0.12252747 0.         3.17670482\n",
      " 0.         0.16177152 2.42195845 1.21136212 2.55878774 0.\n",
      " 0.         2.57662833 0.         0.         0.         0.\n",
      " 3.12772154 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier=SGDRegressor()\n",
    "classifier.fit(X_train,Y_train)\n",
    "predictions=classifier.predict(X_test)\n",
    "predictions[predictions<0]=0\n",
    "result.append(rmse(predictions,Y_test))\n",
    "print(rmse(predictions,Y_test))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2715.24199827, -3022.41982244, -2143.40307537, -2945.78823108,\n",
       "       -4029.32886674, -2287.02233826, -2474.21511097, -2751.90050381,\n",
       "       -3005.78495302, -2382.52944158, -2765.91846727, -3213.88652673,\n",
       "       -2365.03070353, -2729.20081335, -3512.30595261, -1865.55673621,\n",
       "       -2168.66534324, -2365.71581621, -2349.75885206, -2613.40045087,\n",
       "       -2479.2340391 , -2906.85125775, -3145.13963465, -2475.52806218,\n",
       "       -2077.49893002, -1967.72826352, -2723.00774885, -2453.25042539,\n",
       "       -2981.31968391, -2655.81503028, -2780.83799735, -8851.81491048,\n",
       "       -2486.07300318, -2430.37267482, -3140.67140508, -2794.99712692,\n",
       "       -2621.80436391, -4095.82761283, -2337.53236028, -2735.96048473,\n",
       "       -3783.93224287, -3120.38623765, -3953.5015825 , -2151.45545208,\n",
       "       -2454.93077459, -2524.08757007, -2758.55685931, -2160.68593934,\n",
       "       -3642.28232022, -2473.59866386, -1778.74187958, -3229.44468693,\n",
       "       -3409.74014751, -2618.20971823, -2826.18531407, -2157.74592835,\n",
       "       -2324.00385654, -2282.68531183, -1759.17574913, -2331.95611507,\n",
       "       -2580.72888919, -2645.97155892, -2242.44194445, -4945.53176355,\n",
       "       -2231.07442736, -2360.46710135, -1891.61050549, -2168.35191507,\n",
       "       -1945.62725372, -2331.41190349, -2058.38281675, -5025.83979359,\n",
       "       -2360.24093633, -7430.47861426, -2040.70511458, -5938.99477508,\n",
       "       -7547.32029359, -3525.43000887, -1989.81936811, -2423.79246863,\n",
       "       -2209.73365357, -2687.56936061, -2057.65483474, -4476.14069933,\n",
       "       -2883.72752534, -2927.59057212, -2801.05787084, -4504.21598266,\n",
       "       -1784.01769081, -4611.91688706])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_scaler.fit_transform(test_x)\n",
    "sgd_predictions=classifier.predict(test_x.as_matrix())\n",
    "#sgd_predictions[sgd_predictions<0]=0\n",
    "sgd_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfr_model(X, y, max_depth_gsc):\n",
    "    # Perform Grid-Search\n",
    "    gsc = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': range(3, max_depth_gsc),\n",
    "            'n_estimators': (10, 50, 100, 200, 500),\n",
    "        },\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "\n",
    "    grid_result = gsc.fit(X, y)\n",
    "    best_params = grid_result.best_params_\n",
    "\n",
    "    rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"],\n",
    "                                random_state=False, verbose=False, max_features=\"sqrt\")\n",
    "\n",
    "    rfr.fit(X, y)\n",
    "\n",
    "    return rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.46255235, 1.56689362, 1.32813173, 1.41136458, 1.84347705,\n",
       "       2.14151231, 2.22229841, 1.35620486, 3.42834337, 2.12095056,\n",
       "       3.62730313, 4.8261431 , 2.03698355, 1.63641687, 2.40290283,\n",
       "       1.59215923, 2.91935136, 2.79419979, 2.82282914, 2.11528737,\n",
       "       2.27773331, 1.62281789, 1.80087146, 1.48966172, 1.44023693,\n",
       "       1.88797679, 1.39939021, 1.91970438, 2.60255404, 1.46375733,\n",
       "       1.84524866, 1.8046242 , 1.58237135, 1.85412552, 1.69640837,\n",
       "       1.51737939, 1.84013821, 2.39962972, 2.82282914, 3.65001915,\n",
       "       1.55280201, 2.3993972 , 3.20018493, 1.46881103, 2.62263262,\n",
       "       1.58321151, 1.66594897, 2.32079363, 3.23447833, 1.92341628,\n",
       "       2.40411676, 1.31327391, 1.92688841, 2.75703048, 2.13799069,\n",
       "       2.53719379, 2.34081226, 1.77890513, 1.43065523, 1.35677358,\n",
       "       1.56938366, 1.4759314 , 1.42715525, 3.54614433, 1.35266981,\n",
       "       1.84470466, 1.69743791, 2.06972191, 1.90419992, 1.32973118,\n",
       "       2.66807116, 1.54692108, 1.80275574, 2.8775408 , 1.86691836,\n",
       "       2.06144083, 2.7119668 , 2.83925632, 1.61485225, 1.62640453,\n",
       "       2.3115912 , 2.50913219, 1.2873516 , 1.53539067, 2.25772013,\n",
       "       1.66837789, 1.51113063, 1.3478544 , 1.96752596, 3.03371805])"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth_gsc = 15\n",
    "\n",
    "rfr = rfr_model(train_x, train_y, max_depth_gsc)\n",
    "\n",
    "rfr_predictions = rfr.predict(test_x)\n",
    "rfr_predictions[rfr_predictions<0]=0\n",
    "rfr_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9119469026637157 2.0643455595724225\n"
     ]
    }
   ],
   "source": [
    "print(train_y.mean(),rfr_predictions.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=xgb_predictions\n",
    "\n",
    "with open('sample_submission.csv', 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['id','playtime_forever'])\n",
    "    id = 0\n",
    "    for prediction in predictions:\n",
    "        spamwriter.writerow([id, prediction])\n",
    "        id+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
