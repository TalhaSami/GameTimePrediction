{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped Cold War\n",
      "dropped GameMaker\n",
      "dropped Lore-Rich\n",
      "dropped Modern\n",
      "dropped On-Rails Shooter\n",
      "dropped Sexual Content\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import csv\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def rfr_model(X, y, max_depth_gsc):\n",
    "    # Perform Grid-Search\n",
    "    gsc = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': range(3, max_depth_gsc),\n",
    "            'n_estimators': (10, 50, 100, 200, 500),\n",
    "        },\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "\n",
    "    grid_result = gsc.fit(X, y)\n",
    "    best_params = grid_result.best_params_\n",
    "\n",
    "    rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"],\n",
    "                                random_state=False, verbose=False, max_features=\"sqrt\")\n",
    "\n",
    "    rfr.fit(X, y)\n",
    "\n",
    "    return rfr\n",
    "\n",
    "path = \"/Users/Talha/Documents/Master (Big Data)/Semester 3/5001 - Foundations of Data Analytics/Individual Project/\"\n",
    "max_number_of_examples = 10000\n",
    "\n",
    "columns = ['is_free', 'price', 'genres', 'categories', 'tags', 'purchase_date', 'release_date', 'total_positive_reviews', 'total_negative_reviews']\n",
    "labels = ['playtime_forever']\n",
    "\n",
    "columns_train = pd.read_csv(path + \"train.csv\", usecols = columns, nrows=max_number_of_examples).fillna(0)\n",
    "columns_train['is_free'].replace(False, 0, regex=True, inplace=True)\n",
    "columns_train['is_free'].replace(['True'], 1, regex=True, inplace=True)\n",
    "split_columns_train = columns_train[['is_free', 'price', 'total_positive_reviews', 'total_negative_reviews']]\n",
    "split_columns_train = split_columns_train.join(columns_train['genres'].str.get_dummies(sep=',')).join(columns_train['categories'].str.get_dummies(sep=','), lsuffix='_genre', rsuffix='_category').join(columns_train['tags'].str.get_dummies(sep=','), lsuffix='_notTag', rsuffix='_tag')\n",
    "columns_train['release_year'] = pd.DatetimeIndex(columns_train['release_date']).year\n",
    "columns_train['release_month'] = pd.DatetimeIndex(columns_train['release_date']).month\n",
    "columns_train['release_day'] = pd.DatetimeIndex(columns_train['release_date']).day\n",
    "columns_train['release_weekday'] = pd.DatetimeIndex(columns_train['release_date']).dayofweek\n",
    "columns_train['purchase_year'] = pd.DatetimeIndex(columns_train['purchase_date']).year\n",
    "columns_train['purchase_month'] = pd.DatetimeIndex(columns_train['purchase_date']).month\n",
    "columns_train['purchase_day'] = pd.DatetimeIndex(columns_train['purchase_date']).day\n",
    "columns_train['purchase_weekday'] = pd.DatetimeIndex(columns_train['purchase_date']).dayofweek\n",
    "columns_train['purchase_date'] = pd.to_datetime(columns_train['purchase_date'])\n",
    "train_features_data = columns_train[['release_year','release_month','release_day','release_weekday','purchase_year','purchase_month','purchase_day','purchase_weekday']].join(pd.get_dummies(split_columns_train))\n",
    "train_features = train_features_data.columns\n",
    "train_labels_data = pd.read_csv(path + \"train.csv\", usecols = labels, nrows=max_number_of_examples)\n",
    "\n",
    "columns_test = pd.read_csv(path + \"test.csv\", usecols = columns, nrows=max_number_of_examples).fillna(0)\n",
    "columns_test['is_free'].replace(False, 0, regex=True, inplace=True)\n",
    "columns_test['is_free'].replace(True, 1, regex=True, inplace=True)\n",
    "split_columns_test = columns_test[['is_free', 'price', 'total_positive_reviews', 'total_negative_reviews']]\n",
    "split_columns_test = split_columns_test.join(columns_test['genres'].str.get_dummies(sep=',')).join(columns_test['categories'].str.get_dummies(sep=','), lsuffix='_genre', rsuffix='_category').join(columns_test['tags'].str.get_dummies(sep=','), lsuffix='_notTag', rsuffix='_tag')\n",
    "columns_test['release_year'] = pd.DatetimeIndex(columns_test['release_date']).year\n",
    "columns_test['release_month'] = pd.DatetimeIndex(columns_test['release_date']).month\n",
    "columns_test['release_day'] = pd.DatetimeIndex(columns_test['release_date']).day\n",
    "columns_test['release_weekday'] = pd.DatetimeIndex(columns_test['release_date']).dayofweek\n",
    "columns_test['purchase_year'] = pd.DatetimeIndex(columns_test['purchase_date']).year\n",
    "columns_test['purchase_month'] = pd.DatetimeIndex(columns_test['purchase_date']).month\n",
    "columns_test['purchase_day'] = pd.DatetimeIndex(columns_test['purchase_date']).day\n",
    "columns_test['purchase_weekday'] = pd.DatetimeIndex(columns_test['purchase_date']).dayofweek\n",
    "columns_test['purchase_date'] = pd.to_datetime(columns_test['purchase_date'])\n",
    "test_features_data = columns_test[['release_year','release_month','release_day','release_weekday','purchase_year','purchase_month','purchase_day','purchase_weekday']].join(pd.get_dummies(split_columns_test))\n",
    "test_features = test_features_data.columns\n",
    "\n",
    "for train_feature in train_features:\n",
    "    if train_feature not in test_features_data:\n",
    "        test_features_data[train_feature] = 0\n",
    "\n",
    "for test_feature in test_features:\n",
    "    if test_feature not in train_features:\n",
    "        test_features_data.drop(columns=[test_feature], inplace=True)\n",
    "        print(\"dropped \" + test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:58:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE: 0.050846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/Talha/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.40978628,  7.289542  ,  0.565995  ,  3.854947  ,  8.704012  ,\n",
       "        1.7966653 ,  2.0399616 ,  0.07647288,  7.282763  , 13.214488  ,\n",
       "        1.204928  ,  5.6831737 ,  1.4641352 ,  0.6994761 ,  1.9721576 ,\n",
       "        0.1347959 ,  0.70147103,  2.0801146 ,  1.9808253 ,  6.5152626 ,\n",
       "        1.0223874 ,  0.78542435,  1.0969248 ,  1.7140564 ,  0.7539133 ,\n",
       "        1.1415104 ,  1.8233892 ,  5.1672606 ,  3.7001486 ,  1.397624  ,\n",
       "        8.5148735 , 25.411613  ,  3.2255855 ,  1.8240457 ,  5.770246  ,\n",
       "        0.93418527,  3.7800803 ,  6.7130213 ,  2.750111  ,  0.26453367,\n",
       "        7.7229524 ,  2.635842  ,  1.7413142 ,  0.11974877,  2.7805154 ,\n",
       "        1.1580615 ,  6.5359073 ,  2.701671  ,  0.71244115, 10.6803875 ,\n",
       "        1.4903682 ,  2.066809  ,  1.0111904 ,  1.5797563 ,  4.128828  ,\n",
       "        1.8006543 ,  1.4864199 ,  8.097404  ,  0.790539  ,  0.40630394,\n",
       "        4.815832  ,  1.4414582 ,  1.2577515 ,  5.5719476 ,  0.22056511,\n",
       "        0.65224123,  1.0242052 ,  0.3891423 , 18.555786  ,  2.2241988 ,\n",
       "        0.9980431 , 20.772972  ,  4.391101  , 57.236103  ,  2.1182408 ,\n",
       "       22.743559  , 16.28392   ,  3.248365  ,  1.0978508 ,  0.76340383,\n",
       "        0.15367171,  1.675029  ,  0.9713826 ,  3.584539  ,  6.3359876 ,\n",
       "        0.4499832 ,  0.46810666,  6.7733836 ,  6.685167  ,  2.0186944 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=train_features_data.as_matrix(),label=train_labels_data.as_matrix())\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.3,\n",
    "                max_depth = 15, alpha = 10, n_estimators = 30)\n",
    "\n",
    "xg_reg.fit(train_features_data.as_matrix(),train_labels_data.as_matrix())\n",
    "\n",
    "preds = xg_reg.predict(train_features_data.as_matrix())\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(train_labels_data, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "predictions = xg_reg.predict(test_features_data.as_matrix())\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_submission.csv', 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['id','playtime_forever'])\n",
    "    id = 0\n",
    "    for prediction in predictions:\n",
    "        spamwriter.writerow([id, prediction])\n",
    "        id+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
